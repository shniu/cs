# Redis 基础

### Redis 数据结构

Redis 接收到一个键值对操作后，能以微秒级别的速度找到数据，并快速完成操作。Redis 能有这么突出的表现：一方面，这是因为它是内存数据库，所有操作都在内存上完成，内存的访问速度本身就很快（内存访问 100 ns 级别）。另一方面，这要归功于它的数据结构。这是因为，键值对是按一定的数据结构来组织的，操作键值对最终就是对数据结构进行增删改查操作，所以高效的数据结构是 Redis 快速处理数据的基础。

Redis 支持的基础数据类型：String, List, Set, Sorted Set, Hash；这些数据类型中用到的基本数据结构有：简单动态字符串、双向链表、压缩列表、哈希表、跳表和整数数组。我们所说的数据类型是 Redis 中 Value 的类型，Redis 是由键值对构建的内存数据库，键都是字符串，值却有不同的类型表示。

#### Redis 数据库的键值如何组织？

为了实现从键到值的快速访问，Redis 使用了一个哈希表来保存所有键值对。一个哈希表，其实就是一个数组，数组的每个元素称为一个哈希桶。所以，一个哈希表是由多个哈希桶组成的，每个哈希桶中保存了键值对数据。哈希桶中的元素保存的并不是值本身，而是指向具体值的指针。这也就是说，不管值是 String，还是集合类型，哈希桶中的元素都是指向它们的指针。

![](../../.gitbook/assets/image%20%2857%29.png)

Redis 之所以使用哈希表作为全局的 KV 存储，是利用了哈希表的 O\(1\) 时间复杂度来快速查找到键值对的特性；只需要计算键的哈希值，就可以知道它所对应的哈希桶位置，然后就可以访问相应的 entry 元素；这个查找过程主要依赖于哈希计算，和数据量的多少并没有直接关系。也就是说，不管哈希表里有 10 万个键还是 100 万个键，我们只需要一次计算就能找到相应的键。

但是哈希表有个缺点是：随着键值对的增多，hash bucket 的冲突就会随之增加，这个的解决办法是让 bucket 相同的 entry 用链表连接起来，不可避免的一个问题是这个链表有可能会很长，查找数据的效率就会变慢，在 Redis 中这是不允许的，Redis 要非常快的内存操作。

Redis 引入了 rehash 来解决冲突链过长带来的性能下将问题， rehash 的一般做法是：创建一个更大的 hash 表，把老 hash 表的数据复制到新的 hash 表，然后用新的 hash 表提供服务，但是这种方式在 Redis 中的一个问题是大量的内存复制肯能会阻塞 Redis 的线程，无法服务其他请求，会造成短暂的服务中断，无法快速访问数据。

为了解决这个问题，使用**渐进式 rehash**：Redis 默认使用了两个全局哈希表：哈希表 1 和哈希表 2，刚插入数据时，默认使用哈希表 1，此时的哈希表 2 并没有被分配空间。随着数据逐步增多，Redis 开始执行 rehash：

1. 给哈希表 2 分配更大的空间，例如是当前哈希表 1 大小的两倍
2. 把哈希表 1 中的数据重新映射并拷贝到哈希表 2 中, 但是拷贝数据时，Redis 仍然正常处理客户端请求，每处理一个请求时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝到哈希表 2 中；等处理下一个请求时，再顺带拷贝哈希表 1 中的下一个索引位置的 entries
3. 释放哈希表 1 的空间

![&#x6E10;&#x8FDB;&#x5F0F; rehash](../../.gitbook/assets/image%20%2860%29.png)

#### Redis 的底层数据结构

* 动态字符串
* 双向链表
* 压缩列表
* 哈希表
* 跳表
* 整数数组

#### Redis 集合数据类型、操作及应用

* string
* hash
* list
* set
* sorted set
* HyperLogLog
* bitmap
* GEO
* stream

### Redis 网络模型



### Redis 持久化：AOF 和 RDB



### Redis 复制原理：高可靠的基础







